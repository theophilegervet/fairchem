includes:
  - configs/s2ef/all/base.yml

dataset:
  train:
    format: lmdb
    src: /mnt/vast/home/theo/code/fairchem/src/fairchem/data/s2ef/all/train/
    key_mapping:
      y: energy
      force: forces
    transforms:
      normalizer:
        energy:
          mean: -0.7554450631141663
          stdev: 2.887317180633545
        forces:
          mean: 0
          stdev: 2.887317180633545
      FrameAveraging:
        frame_averaging: 3D
        fa_method: stochastic
      
  val:
    src: /mnt/vast/home/theo/code/fairchem/src/fairchem/data/s2ef/all/val_id_small/
    # src: /mnt/vast/home/theo/code/fairchem/src/fairchem/data/s2ef/all/val_id/

model:
  name: baseline
  otf_graph: true
  cutoff: 6.0
  frame_averaging: 3D

  # paper config: 5,595,989 params
  num_interactions: 5
  hidden_channels: 384
  num_filters: 480
  num_gaussians: 104
  tag_hidden_channels: 64
  pg_hidden_channels: 64
  skip_co: concat

  # bigger: 161,570,142 params
  # num_interactions: 30
  # hidden_channels: 1024
  # num_filters: 1024
  # num_gaussians: 256
  # tag_hidden_channels: 256
  # pg_hidden_channels: 256
  # skip_co: add

optim:
  # paper config
  batch_size: 150
  eval_batch_size: 150

  # bigger
  # batch_size: 10
  # eval_batch_size: 10

  num_workers: 8
  lr_initial: 0.0002
  lr_gamma: 0.3
  lr_milestones: # steps at which lr_initial <- lr_initial * lr_gamma
    - 150000
    - 200000
    - 300000
  warmup_steps: 100
  warmup_factor: 0.2
  optimizer: AdamW
  optimizer_params: {"amsgrad": True}
  eval_every: 10000
  max_epochs: 12
  clip_grad_norm: 20
  ema_decay: 0.999
