includes:
  - configs/s2ef/2M/base.yml

model:
  name: baseline

optim:
  batch_size: 6
  eval_batch_size: 6
  num_workers: 8
  lr_initial: 0.0008
  optimizer: AdamW
  optimizer_params: {"amsgrad": True}
  eval_every: 5000
  lr_gamma: 0.3
  lr_milestones: # epochs at which lr_initial <- lr_initial * lr_gamma
    - 145833
    - 187500
    - 229166
  warmup_steps: 100
  warmup_factor: 0.2
  max_epochs: 12
  clip_grad_norm: 20
  ema_decay: 0.999
